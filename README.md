
# ğŸ§  DLOR Project â€“ Traffic Sign Recognition using Deep Learning

![Python](https://img.shields.io/badge/Made%20with-Python-blue.svg?logo=python)
![Jupyter](https://img.shields.io/badge/Notebook-Jupyter-orange.svg?logo=jupyter)
![Dataset](https://img.shields.io/badge/Dataset-GTSRB-yellowgreen)
![Stage](https://img.shields.io/badge/Status-Part%201%20Complete-brightgreen)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

This project is Part 1 of a Deep Learning in Operations Research (DLOR) coursework. It explores traffic sign recognition using the **German Traffic Sign Recognition Benchmark (GTSRB)** dataset. The notebook performs extensive data exploration, visualization, and analysis, laying the groundwork for future model training using convolutional neural networks (CNNs).

---

## ğŸ“˜ Table of Contents

- [Overview](#overview)
- [Dataset](#dataset)
- [Objectives](#objectives)
- [Features & Analyses](#features--analyses)
- [Installation](#installation)
- [Notebook Walkthrough](#notebook-walkthrough)
- [Sample Outputs](#sample-outputs)
- [Learnings & Challenges](#learnings--challenges)
- [Next Steps](#next-steps)
- [Model Analysis & Improvement](#-model-analysis--improvement-roadmap)
- [Author](#author)
- [License](#license)

---

## ğŸ“Œ Overview

Autonomous vehicles and advanced driving systems must detect and understand traffic signs in real time to make informed decisions. This project focuses on preparing, inspecting, and understanding a real-world traffic sign dataset to build a foundation for machine learning models in this domain.

---

## ğŸ“‚ Dataset

**GTSRB** â€“ German Traffic Sign Recognition Benchmark  
- **43** traffic sign classes  
- **50,000+** real-world traffic images  
- Public benchmark from IJCNN 2011  
- Diverse in resolution, lighting, and angle  

---

## ğŸ¯ Objectives

- Import and explore the GTSRB dataset
- Map label indices to human-readable names
- Visualize and analyze images and class distributions
- Prepare a clean, high-resolution dataset sample
- Identify challenges in preprocessing and modeling

---

## ğŸ” Features & Analyses

- âœ… Dataset loading with `deeplake`
- âœ… Grid image visualization per class
- âœ… Class distribution comparison (train/test)
- âœ… Label mapping and feature correlation matrix
- âœ… Image resizing, normalization, and reshaping
- âœ… Duplicate image detection
- âœ… Data augmentation with `ImageDataGenerator`
- âœ… CNN model design and evaluation


---

## ğŸ§ª Notebook Walkthrough

1. **Load Data** â€“ via Deep Lake.
2. **Visual Inspection** â€“ high-res images, missing labels.
3. **Label Mapping** â€“ convert numeric labels to class names.
4. **EDA** â€“ aspect ratios, label counts, correlations.
5. **Preprocessing** â€“ resize, normalize, encode.
6. **Augmentation** â€“ simulate real-world variation.
7. **CNN Model** â€“ conv layers, pooling, dropout, softmax output.

---

## ğŸ–¼ Sample Outputs

- âœ… 43-class image grid
- âœ… Label distribution bar charts
- âœ… Aspect ratio histogram
- âœ… Heatmap of feature correlations
- âœ… Augmented image visualizations
- âœ… CNN architecture summary

---

## ğŸ“ Learnings & Challenges

| Challenge | Solution |
|----------|----------|
| Missing label visual | Explicitly extracted label 39 manually |
| Dataset imbalance | Visualized with bar plots |
| Image variance | Normalized and resized all to 32Ã—32 |
| Redundancy | Detected duplicates using image hashing |

---

## ğŸš€ Next Steps

- Train with deeper CNNs or transfer learning
- Analyze confusion matrix in more detail
- Tune hyperparameters (LR, batch size, dropout)
- Consider K-fold CV for robust validation
- Deploy in simulated environment (optional)

---

## ğŸ§  Model Analysis & Improvement Roadmap

### ğŸ” What Was Done

#### ğŸ§¹ Data Preparation
- Resized all GTSRB images to **32x32 pixels**.
- Normalized pixel values to `[0, 1]`.
- One-hot encoded the labels for multi-class output.

#### ğŸ” Data Augmentation
- Used rotation, zoom, brightness, shift, flip, and shear to increase dataset diversity.

#### ğŸ§  Model Architecture
- Three `Conv2D` + `MaxPooling2D` layers
- One `Dense(128)` + `Dropout(0.5)` + softmax for 43 classes

#### âš™ï¸ Training
- Adam optimizer with early stopping based on validation accuracy

#### ğŸ“ˆ Evaluation
- Confusion matrix and misclassified image visualization

---

### ğŸ”§ What Could Be Improved

#### ğŸ”„ Enhanced Data Augmentation
- Add perspective transforms and occlusion simulation.

#### ğŸ§  Transfer Learning with Pre-Trained Models
- Fine-tune ResNet or MobileNet for better feature extraction.

#### âš–ï¸ Class Weighting
- Balance loss contribution from underrepresented classes.

#### ğŸ” K-Fold Cross-Validation
- Evaluate across multiple splits to reduce overfitting bias.

#### ğŸ“‰ Regularization
- Add L2 penalty to reduce large weight overfitting.

#### ğŸ› Hyperparameter Optimization
- Use grid/random search to tune learning rate, batch size, etc.

#### ğŸ“Š Learning Rate Scheduling
- Adjust LR dynamically during training for better convergence.

---

### ğŸ§­ Next Phase Action Plan

1. Confusion matrix-driven augmentation
2. Transfer learning with MobileNet or ResNet
3. 5-fold cross-validation setup
4. Integrate LR scheduler (`ReduceLROnPlateau`)

---

### âœ… Conclusion

By implementing these improvements, the model will be more robust and reliable for real-world use in autonomous driving and intelligent transport systems. This roadmap bridges the gap between academic prototyping and production-ready deployment.

---

## ğŸ‘¨â€ğŸ’» Author

**Moanish Ashok Kumar**  
Applied AI Student Â· Computer Vision Enthusiast  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/moanish-ashok-kumar-086978272/)

---
